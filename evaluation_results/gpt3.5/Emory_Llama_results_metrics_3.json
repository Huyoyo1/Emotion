{
    "overall": {
        "accuracy": 0.16265060240963855,
        "precision_macro": 0.14238744033773318,
        "recall_macro": 0.14859481376763753,
        "f1_macro": 0.2586614426194109,
        "precision_weighted": 0.17348472969692486,
        "recall_weighted": 0.16265060240963855,
        "f1_weighted": 0.2645906460701065
    },
    "by_class": {
        "neutral": {
            "precision": 0.2755905511811024,
            "recall": 0.20057306590257878,
            "f1_score": 0.23217247097844113,
            "accuracy": 0.2755905511811024,
            "support": 349.0
        },
        "joyful": {
            "precision": 0.22395833333333334,
            "recall": 0.3049645390070922,
            "f1_score": 0.2582582582582582,
            "accuracy": 0.22395833333333334,
            "support": 282.0
        },
        "sad": {
            "precision": 0.09047619047619047,
            "recall": 0.19387755102040816,
            "f1_score": 0.12337662337662336,
            "accuracy": 0.09047619047619047,
            "support": 98.0
        },
        "mad": {
            "precision": 0.0821256038647343,
            "recall": 0.3008849557522124,
            "f1_score": 0.12903225806451613,
            "accuracy": 0.0821256038647343,
            "support": 113.0
        },
        "scared": {
            "precision": 0.15789473684210525,
            "recall": 0.03296703296703297,
            "f1_score": 0.05454545454545455,
            "accuracy": 0.15789473684210525,
            "support": 182.0
        },
        "powerful": {
            "precision": 0.16666666666666666,
            "recall": 0.006896551724137931,
            "f1_score": 0.013245033112582783,
            "accuracy": 0.16666666666666666,
            "support": 145.0
        },
        "peaceful": {
            "precision": 0.0,
            "recall": 0.0,
            "f1_score": 1.0,
            "accuracy": 0.0,
            "support": 159.0
        }
    }
}