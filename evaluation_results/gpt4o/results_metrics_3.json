{
    "overall": {
        "accuracy": 0.42168674698795183,
        "precision_macro": 0.36600759316228537,
        "recall_macro": 0.3693797145199615,
        "f1_macro": 0.34787792122488714,
        "precision_weighted": 0.3964929034009299,
        "recall_weighted": 0.42168674698795183,
        "f1_weighted": 0.3888024395376534
    },
    "by_class": {
        "mad": {
            "precision": 0.34972677595628415,
            "recall": 0.5663716814159292,
            "f1_score": 0.43243243243243246,
            "accuracy": 0.34972677595628415,
            "support": 113.0
        },
        "neutral": {
            "precision": 0.4137323943661972,
            "recall": 0.673352435530086,
            "f1_score": 0.5125408942202835,
            "accuracy": 0.4137323943661972,
            "support": 349.0
        },
        "joyful": {
            "precision": 0.5748987854251012,
            "recall": 0.5035460992907801,
            "f1_score": 0.5368620037807184,
            "accuracy": 0.5748987854251012,
            "support": 282.0
        },
        "scared": {
            "precision": 0.4632352941176471,
            "recall": 0.34615384615384615,
            "f1_score": 0.39622641509433965,
            "accuracy": 0.4632352941176471,
            "support": 182.0
        },
        "sad": {
            "precision": 0.3469387755102041,
            "recall": 0.3469387755102041,
            "f1_score": 0.3469387755102041,
            "accuracy": 0.3469387755102041,
            "support": 98.0
        },
        "powerful": {
            "precision": 0.2535211267605634,
            "recall": 0.12413793103448276,
            "f1_score": 0.16666666666666666,
            "accuracy": 0.2535211267605634,
            "support": 145.0
        },
        "peaceful": {
            "precision": 0.16,
            "recall": 0.025157232704402517,
            "f1_score": 0.04347826086956522,
            "accuracy": 0.16,
            "support": 159.0
        }
    }
}